# Проект: Специфика работы с Netezza 

## Содержание

- [Архитектура Netezza](#архитектура-netezza)
- [Создание тестовых таблиц в Netezza](#создание-тестовых-таблиц-в-netezza)
    - [Предварительная подготовка. Ключи распределения](#предварительная-подготовка-ключи-распределения)
    - [Ключи организации](#ключи-организации)
    - [Создание таблиц с ключами](#создание-таблиц-с-ключами)
    - [Наполнение таблиц данными](#наполнение-таблиц-данными)
    - [Проверка распределения данных по сегментам](#проверка-распределения-данных-по-сегментам)
- [Выполнение стандартных SQL-запросов](#выполнение-стандартных-sql-запросов)
- [Использование встроенных инструментов мониторинга](#использование-встроенных-инструментов-мониторинга)
    - [Команда EXPLAIN](#команда-explain)
    - [Системные представления (_v_qryhist, _v_qrystat)](#системные-представления-v_qryhist-v_qrystat)
    - [Команда SHOW PLANFILE](#команда-show-planfile)
- [Методы оптимизации запросов в Netezza](#методы-оптимизации-запросов-в-netezza)
- [Выводы](#выводы)


## 1. Архитектура Netezza


Netezza — это аналитическая платформа, разработанная для обработки больших объемов данных с высокой производительностью. Основные компоненты архитектуры Netezza включают:


- **Системные узлы**: Netezza использует архитектуру "узел-коллекция", где каждый узел отвечает за определенные задачи обработки данных.

- **Хранилище данных**: Данные хранятся в специализированных устройствах хранения, оптимизированных для быстрого доступа и обработки.

- **Процессоры**: Каждый узел содержит процессоры, FPGA, оперативную память и жесткие диски, которые обрабатывают запросы и выполняют вычисления. Данные, хранящиеся на этих жестких дисках, называются сегментами (data slice).

- **Ключи распределения**: Используются для равномерного распределения данных по узлам, что помогает избежать узких мест и обеспечивает балансировку нагрузки. Позволяет эффективно выполнять параллельные запросы, так как данные, необходимые для выполнения запроса, находятся на одном узле.

- **Zone Maps**: Используются для оптимизации доступа к данным, позволяя избежать ненужного сканирования блоков данных.


## 2. Создание тестовых таблиц в Netezza

### 2.1. Предварительная подготовка. Ключи распределения

Перед созданием таблиц важно знать, что фактическое распределение данных по дискам определяется ключом(ами) распределения Netezza, указанными в определении таблицы. В Netezza доступны два типа методов распределения: хеш-распределение и случайное распределение. Ключ распределения данных устанавливается с помощью оператора `DISTRIBUTE ON`. Если при создании таблицы условие `DISTRIBUTE ON` не указано, то по умолчанию система использует первый столбец в качестве ключа распределения, используя хеш-алгоритм. Максимальное количество столбцов, которые можно указать в условии распределения, составляет четыре.


Факторы, которые стоит учитывать при выборе ключей распределения:


- Чем больше уникальных значений ключа распределения, тем лучше.

- Система распределяет строки с одинаковым значением ключа распределения на один и тот же сегмент данных.

- Параллельная обработка более эффективна, когда строки таблицы равномерно распределены по сегментам данных.

- Таблицы, используемые вместе, должны использовать одни и те же столбцы для своих ключей распределения. Например, в приложении системы продаж идентификатор покупателя в качестве ключа распределения, как для таблицы покупателей, так и для таблицы продаж.

- Если в таблице отсутствует явный столбец кандидат под ключ распределения, то в таком случае подойдет использование распределения случайным образом - `DISTRIBUTE ON RANDOM`.

### 2.2. Ключи организации

Помимо ключей распределения в Netezza существуют ключи организации, которые используются для физической организации данных в таблицах, что позволяет улучшить производительность запросов. Ключ организации данных устанавливается с помощью оператора `ORGANIZE ON`. При выборе столбцов для `ORGANIZE ON` стоит учитывать, какие поля чаще всего используются в условиях `WHERE`, `JOIN` и `GROUP BY`. Это поможет максимизировать выгоду от организации данных. Стоит учитывать, что после загрузки данных в таблицу с `ORGANIZE ON` необходимо выполнить команду `GROOM`, чтобы данные были физически упорядочены в соответствии с ключами организации.

### 2.3. Создание таблиц с ключами

Для тестирования с учетом информации о ключах распределения и организации создадим три таблицы: `products`, `customers` и `sales`.

```sql
CREATE TABLE products (
    product_id INT NOT NULL,
    product_name NVARCHAR(100),
    category NVARCHAR(50),
    price DECIMAL(10, 2)
) DISTRIBUTE ON HASH (product_id) ORGANIZE ON (price);
```
Для таблицы `products` в качестве ключа распределения задан столбец `product_id`, как содержащего наиболее уникальные значения. В качестве ключа организации задан столбец price, как предполагается наиболее часто используемый в условиях фильтрации.

```sql

CREATE TABLE customers (
    customer_id BIGINT NOT NULL,
    first_name NVARCHAR(50),
    last_name NVARCHAR(50),
    email NVARCHAR(100),
    phone NVARCHAR(50)
) DISTRIBUTE ON HASH (customer_id);
```
Для таблицы `customers` в качестве ключа распределения задан столбец `customer_id`, как содержащего наиболее уникальные значения.

```sql
CREATE TABLE sales (
    sale_id BIGINT NOT NULL,
    product_id INT,
    customer_id INT,
    sale_date DATE,
    amount DECIMAL(10, 2),
    quantity INT
) DISTRIBUTE ON HASH (product_id, customer_id) ORGANIZE ON (sale_date);
```
Для таблицы `sales` в качестве ключей распределения заданы столбцы `product_id`, `customer_id`, так как предполагается, что таблица sales будет часто использоваться совместно с таблицами products и customers. В качестве ключа организации установлен столбец `sale_date`, исходя из того, что будет наиболее часто задействован в условиях фильтрации и группировки.

### 2.4. Наполнение таблиц данными 
После разработки схемы таблиц необходимо наполнить их данными. Для этого можно использовать различные инструменты, которые создают тестовые данные. В данном случае будет использован скрипт на Python с применением библиотеки Faker для формирования csv-файлов c последующей загрузкой их в таблицы.

Скрипт для генерации тестовых данных:

```python
from faker import Faker
import random
import pandas as pd

fake = Faker()

# Количество записей для генерации
num_sales = 1000000
num_products = 200000
num_customers = 500000

# Генерация данных для таблицы products
products = []
for i in range(num_products):
    product = {
        'product_id': i + 1,
        'product_name': fake.word(),
        'category': fake.word(),
        'price': round(random.uniform(10.0, 100.0), 2)
    }
    products.append(product)

# Генерация данных для таблицы customers
customers = []
for i in range(num_customers):
    customer = {
        'customer_id': i + 1,
        'first_name': fake.first_name(),
        'last_name': fake.last_name(),
        'email': fake.email(),
        'phone': fake.phone_number()
    }
    customers.append(customer)

# Генерация данных для таблицы sales
sales = []
for i in range(num_sales):
    sale = {
        'sale_id': i + 1,
        'product_id': random.randint(1, num_products),
        'customer_id': random.randint(1, num_customers),
        'sale_date': fake.date_this_year(),
        'amount': round(random.uniform(50.0, 500.0), 2),
        'quantity': random.randint(1, 10)
    }
    sales.append(sale)

# Создание DataFrame для каждой таблицы
products_df = pd.DataFrame(products)
customers_df = pd.DataFrame(customers)
sales_df = pd.DataFrame(sales)

# Сохранение данных в CSV файлы (или можно использовать для вставки в базу данных)
products_df.to_csv('products.csv', index=False)
customers_df.to_csv('customers.csv', index=False)
sales_df.to_csv('sales.csv', index=False)

print("Данные успешно сгенерированы и сохранены в CSV файлы.")
```

Загрузки данных из csv-файла, на примиере таблицы `customers`:

```sql
INSERT INTO customers
SELECT * FROM 
EXTERNAL 'C:\\faker_data\\customers.csv'
USING
(
    ENCODING 'utf-8'
    REMOTESOURCE 'ODBC'
    ESCAPECHAR '\'
    DELIMITER ','
);
```

### 2.5. Проверка распределения данных по сегментам

После загрузки данных можно провести анализ распределения данных по сегментам. С использованием системного столбца `datasliceid` в запросе:

```sql
SELECT 
    datasliceid, 
    COUNT(datasliceid) AS "Rows" 
FROM 
    products  
GROUP BY 
    datasliceid 
ORDER BY 
    "Rows"; 
```
В результате выполнения запроса будет получено количество строк из таблицы `products` на каждом из сегментов данных. Данный показатель позволяет оценить, насколько равномерно данные распределены по сегментам и установить имеются ли перекосы (skew).

#### Методы выявления перекосов в распределении данных

- **Сравнение количества строк**: Посмотрите на количество строк в каждом сегменте. Если один или несколько сегментов имеют значительно больше или меньше строк по сравнению с другими, это может указывать на перекос в распределении данных.

- **Определение пороговых значений**: Установите пороговые значения для определения перекосов. Например, если один сегмент содержит более 20% всех строк, это может быть признаком перекоса.

- **Идентификация аномалий**: Выявите сегменты, которые значительно отличаются от других по количеству строк или средним значениям, и проанализируйте причины этих аномалий.

**Дополнительно**: для определения того, как данные в целом в базе данных распределены по сегментам, можно использовать системное представление - `_V_DSLICE`.
#### Заключение

Создание тестовых таблиц в Netezza — это важный этап, который требует внимательного подхода к проектированию схемы и наполнению данными. Учитывая особенности хранения и обработки данных в Netezza, можно значительно повысить производительность и эффективность выполнения запросов, что является ключевым для аналитических задач.

## 3. Выполнение стандартных SQL-запросов
### Выборка данных

```sql
-- Выборка всех продуктов с ценой выше 50
SELECT * FROM netrebinaa.test_products WHERE price > 50;
```
### Агрегация данных
```sql
-- Подсчет общего количества продаж
SELECT COUNT(*) AS total_sales FROM netrebinaa.test_sales;

-- Подсчет общего дохода от продаж
SELECT SUM(amount) AS total_revenue FROM netrebinaa.test_sales;
```
### Объединение таблиц

```sql
-- Получение информации о продажах с именами клиентов и названиями продуктов
SELECT 
    s.sale_id,
    p.product_name,
    c.first_name,
    c.last_name,
    s.sale_date,
    s.amount,
    s.quantity
FROM 
    netrebinaa.test_sales s
JOIN 
    netrebinaa.test_products p ON s.product_id = p.product_id
JOIN 
    netrebinaa.test_customers c ON s.customer_id = c.customer_id;
```


## 4. Использование встроенных инструментов мониторинга
### 4.1. Команда EXPLAIN

Используйте команду EXPLAIN для анализа плана выполнения запросов. Пример Explain для запроса:
```sql
EXPLAIN SELECT SUM(amount) AS total_revenue FROM sales;
```
Вывод:

```plaintext
QUERY PLANTEXT:

Aggregate (cost=2.2..2.2 rows=1 width=16 conf=0)

   l: Sequential Scan table "SALES" (cost=0.0..1.1 rows=1000000 width=8 conf=100) 
```

Пример вывода EXPLAIN с опцией VERBOSE для подробного вывода плана выполнения:

```plain text
QUERY VERBOSE PLAN:
Node 1.
  [SPU Sequential Scan table "SALES" {(SALES.PRODUCT_ID),(SALES.CUSTOMER_ID)}]
      -- Estimated Rows = 1000000, Width = 8, Cost = 0.0 .. 1.1, Conf = 100.0 
      Projections:
        1: SALES.AMOUNT

Node 2.
  [SPU Aggregate]
      -- Estimated Rows = 1, Width = 16, Cost = 2.2 .. 2.2, Conf = 0.0
      Projections:
        1:SUM(SALES.AMOUNT)
  [SPU Return]
  [HOST Merge Aggs]
  [Host Return]
QUERY PLANTEXT:
Aggregate (cost=2.2..2.2 rows=1 width=16 conf=0)
(xpath_none, locus=spu subject=self)
(spu_send, locus=host subject=self)
(host_merge_agg, locus=host subject=self)
(host_return, locus=host subject=self)
   l: Sequential Scan table "SALES" (cost=0.0..1.1 rows=1000000 width=8 conf=100)  {(SALES.PRODUCT_ID),(SALES.CUSTOMER_ID)}
      (xpath_none, locus=spu subject=self)
```
### 4.2. Системные представления (_V_QRYHIST, _V_QRYSTAT) 

Эти представления позволяют отслеживать историю выполнения запросов и текущие статистики.

```sql
SELECT * FROM _V_QRYHIST WHERE qh_sql LIKE '%JOIN%';

SELECT * FROM _V_QRYSTAT;
```
Пример вывода:
- Здесь будет картинка...


### 4.3. Команда SHOW PLANFILE

Данная команда используется для оценки эффективности использования Zone Maps. Команда указывается после тела запроса, например:

```sql
SELECT SUM(amount) AS total_revenue FROM sales;

SHOW PLANFILE;
```

В результате будет получен план выполнения, по которому возможно выявить, были ли использованы Zone Maps и как они повлияли на производительность запроса.

#### Ключевые метрики для анализа:
- **zmread**: Указывает количество страниц Zone Map, прочитанных во время выполнения запроса.
- **zmhits**: Показывает, сколько из этих чтений было удовлетворено кэшем.
- **table**: Представляет общее количество реальных блоков таблицы.
- **scan**: Отражает количество блоков, которые остались после фильтрации Zone Map.

#### Сравнение метрик:
- Если количество scan меньше количества table, это указывает на то, что Zone Map была эффективна в фильтрации ненужных данных.
- Разница между этими двумя значениями показывает, сколько блоков было исключено благодаря Zone Map, что является прямой мерой ее эффективности.

## 5. Методы оптимизации запросов в Netezza

- **Использование правильных ключей распределения (DISTRIBUTE ON)**: Выбор правильного ключа распределения помогает минимизировать перемещение данных между узлами.

- **Использование ключей организации (ORGANIZE ON)**: Ключи организации помогают оптимизировать порядок хранения данных, что улучшает производительность запросов.

- **Zone Maps**: Zone Maps позволяют избежать ненужного сканирования блоков данных, что значительно ускоряет выполнение запросов.

- **Параллелизм**: Netezza поддерживает параллельную обработку запросов, что позволяет эффективно использовать ресурсы системы.

- **Оптимизация JOIN-ов**: Правильное использование JOIN-ов и выбор подходящих типов соединений (например, HASH JOIN или MERGE JOIN) могут существенно повлиять на производительность запросов.

- **Фильтрация данных**: Применение фильтров на ранних этапах выполнения запроса помогает уменьшить объем обрабатываемых данных, что может значительно ускорить выполнение.

- **Использование временных таблиц**: Временные таблицы могут быть полезны для хранения промежуточных результатов и упрощения сложных запросов, что может улучшить читаемость и производительность.

- **Анализ плана выполнения**: Регулярный анализ плана выполнения запросов и использование системных представлений позволяет выявить узкие места и оптимизировать запросы, основываясь на фактическом поведении системы.

- **Использование агрегатных функций**: Применение агрегатных функций на уровне базы данных может снизить объем передаваемых данных и ускорить выполнение запросов.

- **Разделение таблиц**: Разделение больших таблиц на более мелкие может улучшить производительность запросов, особенно если данные могут быть логически разделены по определенным критериям.

- **Использование встроенных функций**: Использование встроенных функций Netezza может значительно ускорить выполнение запросов по сравнению с пользовательскими функциями.


### Применение методов на практике
**Выбор правильного ключа распределения**

При создании таблиц важно выбирать ключи распределения, которые минимизируют перемещение данных.
Выявление перекосов в данных, распределенных по сегментам (dataslices)

Анализ распределения данных по сегментам позволяет выявить возможные перекосы, которые могут негативно сказаться на производительности запросов. Для этого можно использовать системные представления, такие как _V_DSLICE, чтобы оценить, как данные распределены по различным сегментам.

## 6. Выводы

В ходе проекта были рассмотрены ключевые аспекты хранения данных, мониторинга и оптимизации в Netezza. Основные выводы включают:

Правильная архитектура и распределение данных критически важны для достижения высокой производительности.
Использование встроенных инструментов мониторинга позволяет эффективно отслеживать и анализировать выполнение запросов.
Оптимизация запросов с помощью правильных ключей распределения и организации данных может значительно улучшить время выполнения запросов.
Регулярный анализ распределения данных помогает выявлять и устранять проблемы, связанные с производительностью.

Эти аспекты являются основой для эффективного использования Netezza в аналитических задачах и обеспечивают высокую производительность при работе с большими объемами данных.
